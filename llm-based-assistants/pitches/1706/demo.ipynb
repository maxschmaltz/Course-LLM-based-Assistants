{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b014ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_chatbot.main import init_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9993733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = init_pipeline(\n",
    "    ... # your parameters here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ce8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: straightforward query\n",
    "query = \"What is the difference between supervised and unsupervised learning?\"\n",
    "pipeline.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab042e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: straightforward query\n",
    "query = \"How do I fine-tune a GPT model on a custom dataset?\"\n",
    "pipeline.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: simple query\n",
    "query = \"What is the final submission deadline for the OpenAI to Z Challenge?\"\n",
    "pipeline.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: simple query\n",
    "query = \"Are team entries allowed in the OpenAI to Z Challenge?\"\n",
    "pipeline.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf96609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5: simple query\n",
    "query = \"How is the leaderboard score calculated for the OpenAI to Z Challenge?\"\n",
    "pipeline.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6: complex query\n",
    "query = \"What constraints are there on using external datasets, and how might that affect a submission using proprietary data?\"\n",
    "pipeline.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cdd286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7: complex query\n",
    "query = \"Describe the scoring criteria and how creativity and technical quality interact in the evaluation process.\"\n",
    "pipeline.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8: complex query\n",
    "query = \"If I build a chatbot that performs A-Z tasks but use open-source models, how would this affect eligibility and evaluation?\"\n",
    "pipeline.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda6f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9: unanswerable query\n",
    "query = \"What was the internal motivation behind choosing the A-Z format for OpenAI to Z challenge?\"\n",
    "pipeline.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d47f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10: unanswerable query\n",
    "query = \"How many total submissions did the OpenAI to Z Challenge receive in its first week?\"\n",
    "pipeline.run(query)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
